{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Vertex AI의 Agent Engine을 사용해서 Agent 빌드 및 배포하기\n",
    "* Intro to Building and Deploying an Agent with Agent Engine in Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fagent-engine%2Fintro_agent_engine.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>      \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/agent-engine/intro_agent_engine.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/4jeQzJW\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/intro_agent_engine.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                     |                                                      |\n",
    "|---------------------|------------------------------------------------------|\n",
    "| Author(s)           | [Kristopher Overholt](https://github.com/koverholt)    |\n",
    "| Korean version      | [T Kim](https://github.com/aimldl)                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrkcqHrrwMAo"
   },
   "source": [
    "## 목표\n",
    "- 이번 핸즈온 랩에서는 Python용 Vertex AI SDK를 사용해서 에이전트(모델, 도구 및 추론)를 빌드하고 배포하는 방법을 학습합니다.\n",
    "    - 대규모 언어모델: Gemini 2.0 Flash\n",
    "    - 도구: Python 함수\n",
    "    - 오케스트레이션: LangChain\n",
    "\n",
    "### 진행할 작업\n",
    "- Python용 Vertex AI SDK 설치\n",
    "- Vertex AI SDK를 사용하여 간단한 에이전트의 구성 요소를 빌드\n",
    "- 배포 전 로컬 테스트. (로컬환경에서 에이전트가 잘 동작하는지 확인)\n",
    "- Vertex AI에 배포 및 테스트 (리모트 환경에 에이전트를 배포하고 확인)\n",
    "- 맞춤/커스텀으로 에이전트의 각 계층인 모델, 도구, 오케스트레이션을 설정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9nEPojogw-g"
   },
   "source": [
    "### 비용\n",
    "Google Cloud의 Vertex AI는 유료입니다.\n",
    "- [Vertex AI 가격](https://cloud.google.com/vertex-ai/pricing?hl=ko)을 참고하세요.\n",
    "- 예상 사용량을 알고 계시면 [가격 계산기](https://cloud.google.com/products/calculator/)로 비용 견적을 계산해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkHPv2myT2cx"
   },
   "source": [
    "## 개요\n",
    "\n",
    "### 문제 > 대규모 언어 모델(LLM)의 한계\n",
    "LLM이 상용화되며 다양한 분야에 적용되며 여러가지 문제를 해결하는 데 효과적인 것이 검증되었습니다.\n",
    "하지만 이 과정에서 아래와 같은 단점이 발견됐습니다.\n",
    "1. 오래된 지식: LLM은 학습 후 고정되므로, 이후에 생성된 최신 지식을 반영하지 못 합니다.\n",
    "2. 외부 데이터 접근 불가: 외부 데이터를 쿼리하거나 수정할 수 없습니다.\n",
    "\n",
    "### 해법 > 왜 함수 호출인가?\n",
    "- 이런 LLM의 단점을 해결하는 방안 중 하나로 함수 호출이 제안됐습니다.\n",
    "- 함수 호출은 도구 사용 (tool use)라고도 합니다. 모델이 외부의 도구 (API 및 함수)를 사용할 수 있기 때문입니다.\n",
    "\n",
    "#### Gemini\n",
    "Gemini는 Google DeepMind에서 개발한 생성형 AI 모델 제품군으로, 멀티모달 사용 사례를 위해 설계되었습니다.\n",
    "\n",
    "[지원되는 모델](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling?hl=ko#supported_models)\n",
    "다음 모델은 함수 호출 지원을 제공합니다.\n",
    "\n",
    "| 모델                 | 병렬 함수 호출 | 강제 함수 호출 |\n",
    "|----------------------|----------------|----------------|\n",
    "| Gemini 2.0 Flash     | ✓              | ✓              |\n",
    "| Gemini 2.0 Flash-Lite | ✓              | ✓              |\n",
    "\n",
    "### 함수 호출\n",
    "- 함수 호출은 LLM이 미리 정의된 외부 함수나 API를 활용해서, 학습 데이터를 넘어선 정보를 참조하거나 특정 작업을 수행하도록 하는 기능입니다. \n",
    "- 이를 통해 LLM은 실시간 정보에 접근하고 외부 시스템과 상호작용하며 그 한계를 효과적으로 보완할 수 있게 됩니다.\n",
    "- 자세한 내용은 [함수 호출 (Function calling)](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling?hl=ko)을 참고하세요.\n",
    "\n",
    "#### 예시 > LLM이 get_weather 함수를 호출\n",
    "LLM이 get_weather라는 날씨 조회 함수를 사용하는 과정을 통해 함수 호출의 작동 방식을 단계별로 살펴보겠습니다.\n",
    "\n",
    "1. 사용자 질문 및 LLM의 함수 사용 결정\n",
    "- 사용자가 LLM에게 \"오늘 서울 날씨 어때?\"와 같이 실시간 정보가 필요한 질문을 합니다.\n",
    "- LLM은 질문에 답하기 위해 외부의 날씨 정보를 가져올 수 있는 get_weather 함수를 사용해야 한다고 판단합니다.\n",
    "\n",
    "2. LLM의 실행 요청 생성 (함수 직접 호출이 아님)\n",
    "- LLM이 JSON 응답이 담긴 텍스트 응답을 생성해서 사용자에게 답변합니다.\n",
    "- 예를 들어, \n",
    "```json\n",
    "{\n",
    "  \"function_name\": \"get_weather\",\n",
    "  \"parameters\": {\n",
    "    \"location\": \"서울\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "- LLM은 사용자의 시스템 혹은 애플리케이션이 수행할 명확한 지시사항을 담은 구조화된 데이터를 생성합니다.\n",
    "  - 어떤 함수를 어떤 인자(parameter)로 호출하는지 명확히 지시합니다.\n",
    "  - 구조화된 데이터는 일반적으로 JSON 형식입니다.\n",
    "  - [중요] LLM이 get_weather 함수를 직접 실행하지 않습니다.\n",
    "\n",
    "3. 사용자 시스템의 외부 함수/API 실제 호출\n",
    "- 사용자의 시스템은 LLM이 생성한 JSON 데이터를 해석합니다.\n",
    "- \"서울\"이라는 위치 정보를 가지고, get_weather 함수를 실행합니다.\n",
    "- get_weather함수는 외부의 날씨 정보 서비스 API에 해당 지역의 날씨 데이터를 요청합니다.\n",
    "- 이 API 호출을 통해 \"서울: 22°C, 맑음\"과 같은 정보를 획득합니다.\n",
    "\n",
    "4. 사용자 시스템은 외부 API 호출 결과를 LLM에 전달. LLM은 최종 답변 생성\n",
    "- 외부 API에서 받은 실제 날씨 정보(\"서울: 22°C, 맑음\")를 LLM에 전달합니다.\n",
    "- LLM은 이 정보를 바탕으로 사용자의 원래 질문에 대한 최종 답변을 문장으로 생성합니다.\n",
    "- 예: \"오늘 서울의 날씨는 맑고, 현재 기온은 22°C입니다.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [함수 호출의 사용 사례](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling?hl=ko#use-cases)\n",
    "\n",
    "| 사용 사례                      | 예시                                                                                                                                                                                                                                                                                         |\n",
    "| :----------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| 외부 API 호출                  | - 기상청 API에서 날씨 정보 가져오기 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb))<br>- 환율 API로 통화 변환 ([Codelab](https://codelabs.developers.google.com/codelabs/gemini-function-calling?hl=ko))<br>- 주소를 위도/경도 좌표로 변환 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb)) |\n",
    "| 함수 호출 구성 및 제어           | - 원시 로그 데이터에서 구조화된 항목 추출 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb))<br>- 사용자 입력에서 단일 또는 여러 파라미터 추출 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/function_calling_data_structures.ipynb))<br>- 함수 호출에서 목록 및 중첩된 데이터 구조 처리 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/function_calling_data_structures.ipynb)) |\n",
    "| 함수 호출 동작 처리              | - 병렬 함수 호출 및 응답 처리 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/parallel_function_calling.ipynb))<br>- 모델이 호출할 수 있는 함수 및 시기 관리 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/forced_function_calling.ipynb)) |\n",
    "| 자연어를 이용한 데이터베이스 쿼리 | - 자연어 질문을 BigQuery용 SQL 쿼리로 변환 ([샘플 앱](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/function-calling/sql-talk-app))                                                                                                                                    |\n",
    "| 멀티모달 함수 호출               | - 이미지, 동영상, 오디오, PDF를 입력으로 사용하여 함수 호출 트리거 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/multimodal_function_calling.ipynb))                                                                                             |\n",
    "| 고급 챗봇 빌드                 | - 제품 및 서비스에 대한 고객 질문 답변 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb))<br>- 회사에 대한 재무 및 소식 질문에 답변하는 어시스턴트 만들기 ([노트북 튜토리얼](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/use_case_company_news_and_insights.ipynb)) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 호출 > 요약\n",
    "- LLM은 함수 호출을 통해 자신의 학습 데이터에 없는 최신 정보를 활용하거나, 외부 시스템과의 상호작용을 통해 사용자의 다양한 요구에 보다 정확하고 풍부한 답변을 제공할 수 있게 됩니다.\n",
    "- LLM이 함수를 직접 실행하는 것이 아니라 구조화된 데이터를 생성해서 사용자, 즉 개발자의 시스템이 사용/해석 가능한 포맷으로 수행할 지시사항을 '요청'합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 용어 > 동의어\n",
    "> - 일반 명사: 대규모 언어 모델, LLM, 생성형 모델, 혹은 줄여서 모델.\n",
    "> - 고유 명사: Gemini, Gemma, ChatGPT, Llama 등\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertex AI의 Agent Engine(에이전트 엔진)\n",
    "(이전 명칭) Vertex AI 기반 LangChain 또는 Vertex AI Reasoning Engine (추론 엔진)\n",
    "\n",
    "- 개발자가 프로덕션 환경에서 AI 에이전트의 배포, 관리 및 확장을 지원하는 완전 관리형 서비스입니다. \n",
    "- 사용자는 지능적이고 임팩트 있는 애플리케이션을 만드는 데 집중할 수 있습니다.\n",
    "\n",
    "<img width=\"60%\" src=\"https://storage.googleapis.com/github-repo/generative-ai/gemini/agent-engine/images/agent-engine-overview.png\" alt=\"Agent Engine on Vertex AI\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Gemini 함수 호출](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling?hl=ko)을 통해 도구로 사용될 Python 함수를 정의할 수 있습니다.\n",
    "2. 에이전트, 모델, 도구를 정의하고, 프롬프트 및 예제를 모듈식으로 관리할 수 있습니다.\n",
    "- Vertex AI의 Gemini 모델용 GenAI SDK와 통합되어, 프롬프트, 에이전트와 예제를 모듈식으로 관리할 수 있습니다. \n",
    "- Vertex AI의 Python SDK를 통해 Gemini 모델을 사용할 수 있습니다.\n",
    "\n",
    "3. Vertex AI에 배포할 수 있습니다.\n",
    "- LangChain, LlamaIndex 또는 기타 Python 프레임워크와 호환됩니다.\n",
    "- LLM에 위임할 추론 (reasoning)의 양과 맞춤형 코드로 처리할 양을 유연하게 선택할 수 있도록 지원합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11Gu7qNgx1p"
   },
   "source": [
    "## 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Python용 GenAI SDK 설치하기\n",
    "- Python용 GenAI SDK 최신 버전, LangChain, Agent Engine 및 종속된 관련 패키지를 설치합니다.\n",
    "- 참고: 종속된 관련 패키지를 설치할 때, pip 패키지 오류가 발생하면 셀을 다시 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai\n",
    "%pip install --upgrade --quiet langchain\n",
    "%pip install --upgrade --quiet langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### 런타임 재시작\n",
    "- 새로 설치된 패키지를 사용하려면 런타임을 재시작해야 합니다.\n",
    "- 다음 셀을 실행하면 이 Jupyter 런타임에서 커널을 다시 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XRvKdaPDTznN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### (Colab only) 노트북 환경 인증 \n",
    "- [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)를 사용할 경우 이 단계는 필요하지 않습니다.\n",
    "- Google Colab를 사용할 경우, 다음 셀을 실행해서 이 노트북 환경을 인증하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### [설정] Google Cloud 프로젝트 정보 설정 및 Vertex AI SDK 초기화\n",
    "- Google Cloud의 프로젝트를 생성해야 합니다.\n",
    "- Vertex AI를 사용하려면 Vertex AI API를 활성화해야 합니다.\n",
    "\n",
    "자세한 내용은 [프로젝트 및 개발 환경 설정](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)하는 방법을 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Vertex AI API를 활성화](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
    "https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/google_cloud-enable_the_vertex_ai_api-1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/google_cloud-enable_the_vertex_ai_api-2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. 노트북 셋업 /프로젝트 관련 정보를 설정하기\n",
    "- Set up the notebook\n",
    "\n",
    "```\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"[your-region]\"  # @param {type:\"string\"}\n",
    "STAGING_BUCKET = \"gs://[your-staging-bucket]\"  # @param {type:\"string\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-02-ab08c7060001\"  # @param {type:\"string\"}\n",
    "LOCATION = \"europe-west1\"  # @param {type:\"string\"}\n",
    "STAGING_BUCKET = \"gs://qwiklabs-gcp-02-ab08c7060001\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. 에이전트 빌드 및 배포\n",
    "- Build and deploy an agent\n",
    "\n",
    "Python용 Gen AI SDK를 사용하여 에이전트를 빌드하고 배포합니다. \n",
    "\n",
    "### 에이전트의 세 가지 구성 요소\n",
    "1. 모델(Model): Gemini Pro 모델\n",
    "2. 도구(Tools): Python 함수\n",
    "\n",
    "    모델이 호출을 지시할 수 있는 Python 함수\n",
    "3. 오케스트레이션(Orchestration): LangChain \n",
    "\n",
    "    추론(reasoning)의 오케스트레이션/조정을 위한 프레임워크 \n",
    "\n",
    "### 실행 단계 (Steps)\n",
    "- Step 1. 노트북에서 모델, 도구 및 오케스트레이션을 정의합니다.\n",
    "- Step 2. 에이전트를 로컬에서 테스트합니다.\n",
    "- Step 3. Vertex AI에 에이전트를 배포합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e5c96372296"
   },
   "source": [
    "### 에이전트 빌드 및 배포하기 > 예시\n",
    "- Example: Build and deploy an agent\n",
    "\n",
    "아래 섹션을 실행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXHfaVS66_01",
    "tags": []
   },
   "source": [
    "#### 라이브러리 가져오기\n",
    "- Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai import agent_engines\n",
    "from vertexai.preview.reasoning_engines import LangchainAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43c61bf4c3f5"
   },
   "source": [
    "#### 모델 정의하기\n",
    "- Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f685ca44c1e9"
   },
   "source": [
    "에이전트를 만들 때 필요한 첫 번째 구성요소는 사용할 생성형 모델입니다.\n",
    "\n",
    "<img width=\"40%\" src=\"https://storage.googleapis.com/github-repo/generative-ai/gemini/agent-engine/images/agent-stack-1.png\" alt=\"Components of an agent in Agent Engine on Vertex AI\" />\n",
    "\n",
    "Gemini 2.0 Flash 모델을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "921890fcb875",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"gemini-2.5-pro-preview-05-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"gemini-2.5-pro-preview-03-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"gemini-2.5-pro-exp-03-25\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60eba5468448"
   },
   "source": [
    "#### 도구 (tools) 정의하기 > Python 함수 정의\n",
    "- Define Python functions (tools)\n",
    "\n",
    "에이전트의 두 번째 구성 요소는 도구 (tools) 입니다.\n",
    "\n",
    "<img width=\"40%\" src=\"https://storage.googleapis.com/github-repo/generative-ai/gemini/agent-engine/images/agent-stack-2.png\" alt=\"Components of an agent in Agent Engine on Vertex AI\" />\n",
    "\n",
    "- 생성형 모델은 도구를 통해 외부 시스템과 상호작용할 수 있습니다.\n",
    "    -  외부 시스템의 예: 기타 API, 데이터베이스, 문서 저장소 등\n",
    "    -  이런 외부 시스템에서 정보를 얻거나, 작업을 수행할 수 있습니다.\n",
    "-  예를 들어, 기상청 API에는 생성형 모델에 없는 최신의 날씨 정보가 있습니다.\n",
    "-  이런 최신 정보를 외부 시스템인 기상청 API에서 얻을 수 있습니다.\n",
    "\n",
    "> 주의: 도구는 영어로 \"tools\"로 복수입니다.\n",
    "> - 즉, 사용자는 하나 또는 여러개의 도구를 제공할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 예제에서는 외부 시스템 \"실시간 환율 정보 API\"를 호출하는 `get_exchange_rate` 함수를 정의합니다.\n",
    "- 이 함수는 호출을 위해 `requests` 라이브러리를 사용합니다.\n",
    "- 디폴드 값은 USD와 EUR의 최신 환율을 얻어옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ff7991bf37bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_exchange_rate(\n",
    "    currency_from: str = \"USD\",\n",
    "    currency_to: str = \"EUR\",\n",
    "    currency_date: str = \"latest\",\n",
    "):\n",
    "    \"\"\"Retrieves the exchange rate between two currencies on a specified date.\"\"\"\n",
    "    import requests\n",
    "\n",
    "    response = requests.get(\n",
    "        f\"https://api.frankfurter.app/{currency_date}\",\n",
    "        params={\"from\": currency_from, \"to\": currency_to},\n",
    "    )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"실시간 환율 정보 API\"는 https://api.frankfurter.app/{currency_date}를 사용합니다.\n",
    "\n",
    "https://api.frankfurter.app/2025-05-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/api_for_exchange_rate-https_api_frankfurter_app_2025-05-15.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "971f56c167e7"
   },
   "source": [
    "#### 테스트 > Python 함수의 동작 확인 \n",
    "샘플 입력으로 예상대로 작동하는지 확인합니다.\n",
    "- USD: US Dollar\n",
    "- SEK: Swedish Krona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4ae49a2ccd2e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': 1.0, 'base': 'USD', 'date': '2025-05-20', 'rates': {'SEK': 9.682}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_exchange_rate(currency_from=\"USD\", currency_to=\"SEK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- USD: US Dollar\n",
    "- KRW: (South) Korean Won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': 1.0, 'base': 'USD', 'date': '2025-05-20', 'rates': {'KRW': 1394.62}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_exchange_rate(currency_from=\"USD\", currency_to=\"KRW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/exchange_rate-google_search-usd-krw.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35ca52a9021c"
   },
   "source": [
    "### 에이전트 정의하기\n",
    "에이전트의 세 번째 구성 요소는 추론 계층 (reasoning layer)입니다.\n",
    "\n",
    "<img width=\"40%\" src=\"https://storage.googleapis.com/github-repo/generative-ai/gemini/agent-engine/images/agent-stack-3.png\" alt=\"Components of an agent in Agent Engine on Vertex AI\" />\n",
    "\n",
    "- \"사용자가 제공한 도구\"를 에이전트가 사용하는데 도움을 줍니다.\n",
    "\n",
    "> 주의: 도구는 영어로 \"tools\"로 복수입니다.\n",
    "\n",
    "- 이는 최종 사용자가 상위 수준 목표를 달성하는 데 도움이 되도록 제공한 도구를 에이전트가 사용하는 데 도움을 줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: 왜 추론 계층이 필요한가요?\n",
    "A: \n",
    "- 추론 계층 없이 Gemini와 함수 호출을 단독으로 사용한다면, 애플리케이션 코드 내에서 함수 및 API 호출 프로세스를 직접 처리해야 합니다. \n",
    "- 또, 함수 호출 코드가 실패나 잘못된 요청에 대해 복원력을 갖도록 재시도 및 추가 로직을 구현해야 합니다.\n",
    "\n",
    "\n",
    "```bash\n",
    "# 앞서 import된 라이브러리를 편의를 위해 복사함\n",
    "  ...\n",
    "from vertexai.preview.reasoning_engines import LangchainAgent\n",
    "```\n",
    "여기서는 Vertex AI SDK의 에이전트 엔진에서 제공하는 LangChain 에이전트 템플릿을 사용해서 지금까지 구축한 모델, 도구 및 추론을 하나로 통합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "68bc1b395f9d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = LangchainAgent(\n",
    "    model=model,\n",
    "    tools=[get_exchange_rate],\n",
    "    agent_executor_kwargs={\"return_intermediate_steps\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68a527f87e42"
   },
   "source": [
    "### 에이전트 로컬 테스트\n",
    "* Test your agent locally\n",
    "\n",
    "이제 로컬 환경에서 예상대로 작동하는지 테스트를 진행합니다.\n",
    "- 배포 전 모델과 에이전트의 동작을 로컬에서 테스트합니다.\n",
    "- 이를 통해 예상대로 작동하는지 확인합니다\n",
    "\n",
    "에이전트의 모든 핵심 구성 요소가 준비되었으므로, `.query`를 사용해서 에이전트에 프롬프트를 전송합니다. 입력 프롬프트와 생성된 요약 출력 사이에서 에이전트가 수행한 중간 단계도 포함합니다. 기본 모드에서 에이전트는 입력을 처리하고 **완료 시 전체 에이전트 출력을 단일 응답으로 반환합니다**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "e0c5c699de12",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised NotFound: 404 Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised NotFound: 404 Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised NotFound: 404 Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 8.0 seconds as it raised NotFound: 404 Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 10.0 seconds as it raised NotFound: 404 Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found..\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:170\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     prefetch_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callable_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_prefetch_first_result_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_StreamingResponseIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefetch_first_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefetch_first\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:92\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__init__\u001b[0;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prefetch_first_result:\n\u001b[0;32m---> 92\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stored_first_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# It is possible the wrapped method isn't an iterable (a grpc.Call\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# for instance). If this happens don't store the first result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:543\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:969\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:64.233.167.95:443 {created_time:\"2025-05-20T19:15:06.960521377+00:00\", grpc_status:5, grpc_message:\"Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[1;32m      2\u001b[0m today \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(date\u001b[38;5;241m.\u001b[39mtoday())\n\u001b[0;32m----> 3\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the exchange rate from USD to SEK \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtoday\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py:614\u001b[0m, in \u001b[0;36mLangchainAgent.query\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runnable:\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_up()\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m langchain_load_dump\u001b[38;5;241m.\u001b[39mdumpd(\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 157\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1620\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1620\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1628\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1629\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1630\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1326\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1319\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1326\u001b[0m         [\n\u001b[1;32m   1327\u001b[0m             a\n\u001b[1;32m   1328\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1329\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1330\u001b[0m                 color_mapping,\n\u001b[1;32m   1331\u001b[0m                 inputs,\n\u001b[1;32m   1332\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1333\u001b[0m                 run_manager,\n\u001b[1;32m   1334\u001b[0m             )\n\u001b[1;32m   1335\u001b[0m         ]\n\u001b[1;32m   1336\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1326\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1319\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1326\u001b[0m         [\n\u001b[1;32m   1327\u001b[0m             a\n\u001b[1;32m   1328\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1329\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1330\u001b[0m                 color_mapping,\n\u001b[1;32m   1331\u001b[0m                 inputs,\n\u001b[1;32m   1332\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1333\u001b[0m                 run_manager,\n\u001b[1;32m   1334\u001b[0m             )\n\u001b[1;32m   1335\u001b[0m         ]\n\u001b[1;32m   1336\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:1354\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1353\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1354\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:577\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m             final_output \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:3424\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   3418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   3419\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3422\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3423\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3424\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:3410\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3403\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   3404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   3405\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3408\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3409\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3410\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   3411\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3412\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   3413\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   3414\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3415\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:2205\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 2205\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2206\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   2207\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:3372\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3370\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 3372\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:1419\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1416\u001b[0m final: Input\n\u001b[1;32m   1417\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ichunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;66;03m# The default implementation of transform is to buffer input and\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m     \u001b[38;5;66;03m# then call stream.\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;66;03m# It'll attempt to gather all input into a single chunk using\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;66;03m# the `+` operator.\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;66;03m# If the input is not addable, then we'll assume that we can\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# only operate on the last chunk,\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m# and we'll iterate until we get to the last chunk.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1428\u001b[0m         final \u001b[38;5;241m=\u001b[39m ichunk\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:5632\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5625\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   5627\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   5631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 5632\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   5633\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5635\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5636\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:1437\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1437\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:498\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m input_messages \u001b[38;5;241m=\u001b[39m _normalize_messages(messages)\n\u001b[1;32m    497\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((_LC_ID_PREFIX, \u001b[38;5;28mstr\u001b[39m(run_manager\u001b[38;5;241m.\u001b[39mrun_id)))\n\u001b[0;32m--> 498\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(input_messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m run_id\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py:1861\u001b[0m, in \u001b[0;36mChatVertexAI._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_non_gemini(\n\u001b[1;32m   1858\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1859\u001b[0m     )\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1861\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_gemini(\n\u001b[1;32m   1862\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1863\u001b[0m )\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py:1874\u001b[0m, in \u001b[0;36mChatVertexAI._stream_gemini\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_stream_gemini\u001b[39m(\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1868\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1871\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1872\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ChatGenerationChunk]:\n\u001b[1;32m   1873\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request_gemini(messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1874\u001b[0m     response_iter \u001b[38;5;241m=\u001b[39m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1875\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_generate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_exponential_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_exponential_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1884\u001b[0m     total_lc_usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1885\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response_chunk \u001b[38;5;129;01min\u001b[39;00m response_iter:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py:652\u001b[0m, in \u001b[0;36m_completion_with_retry\u001b[0;34m(generation_method, max_retries, run_manager, wait_exponential_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    647\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    648\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_gemini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[1;32m    651\u001b[0m )\n\u001b[0;32m--> 652\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py:645\u001b[0m, in \u001b[0;36m_completion_with_retry.<locals>._completion_with_retry_inner\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry_inner\u001b[39m(generation_method: Callable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2532\u001b[0m, in \u001b[0;36mPredictionServiceClient.stream_generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2531\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2532\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2537\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:174\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[1;32m    171\u001b[0m         result, prefetch_first_result\u001b[38;5;241m=\u001b[39mprefetch_first\n\u001b[1;32m    172\u001b[0m     )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Publisher Model `projects/qwiklabs-gcp-02-ab08c7060001/locations/europe-west1/publishers/google/models/gemini-2.5-pro-preview-03-25` not found."
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "today = str(date.today())\n",
    "agent.query(input=f\"What's the exchange rate from USD to SEK {today}?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1cf06f5fa46"
   },
   "source": [
    "기본 쿼리 모드(default query mode) 외에 `.stream_query` 메서드를 사용할 수 있습니다.\n",
    "\n",
    "`.stream_query`\n",
    "- 에이전트는 응답을 생성되는 즉시 여러 조각으로 나누어 보냅니다.\n",
    "- 에이전트의 동작을 (함수 호출이나 중간 단계의) 결과를 실시간으로 관찰할 수 있습니다.\n",
    "- 에이전트가 모든 하위 작업을 완료할 때까지 기다리지 않아도 됩니다.\n",
    "- 디버깅 목적이나 최종 사용자에게 실시간 업데이트를 제공하는 데 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7a931f086fc9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------\n",
      "\n",
      "Action:\n",
      "\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'agent', 'ToolAgentAction'], 'kwargs': {'tool': 'get_exchange_rate', 'tool_input': {'currency_to': 'SEK', 'currency_date': '2025-05-20', 'currency_from': 'USD'}, 'log': \"\\nInvoking: `get_exchange_rate` with `{'currency_to': 'SEK', 'currency_date': '2025-05-20', 'currency_from': 'USD'}`\\n\\n\\n\", 'type': 'AgentActionMessageLog', 'message_log': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'content': '', 'additional_kwargs': {'function_call': {'name': 'get_exchange_rate', 'arguments': '{\"currency_to\": \"SEK\", \"currency_date\": \"2025-05-20\", \"currency_from\": \"USD\"}'}}, 'response_metadata': {'safety_ratings': [], 'usage_metadata': {}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-pro-preview-05-06'}, 'type': 'AIMessageChunk', 'id': 'run--7876090c-6a73-4d2c-905f-9bad82d1940a', 'tool_calls': [{'name': 'get_exchange_rate', 'args': {'currency_to': 'SEK', 'currency_date': '2025-05-20', 'currency_from': 'USD'}, 'id': 'e59f289a-256a-42cc-b6d9-0510512d0b78', 'type': 'tool_call'}], 'usage_metadata': {'input_tokens': 56, 'output_tokens': 26, 'total_tokens': 177}, 'tool_call_chunks': [{'name': 'get_exchange_rate', 'args': '{\"currency_to\": \"SEK\", \"currency_date\": \"2025-05-20\", \"currency_from\": \"USD\"}', 'id': 'e59f289a-256a-42cc-b6d9-0510512d0b78', 'index': None, 'type': 'tool_call_chunk'}], 'invalid_tool_calls': []}}], 'tool_call_id': 'e59f289a-256a-42cc-b6d9-0510512d0b78'}}]\n",
      "\n",
      "------\n",
      "\n",
      "Message:\n",
      "\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'content': '', 'additional_kwargs': {'function_call': {'name': 'get_exchange_rate', 'arguments': '{\"currency_to\": \"SEK\", \"currency_date\": \"2025-05-20\", \"currency_from\": \"USD\"}'}}, 'response_metadata': {'safety_ratings': [], 'usage_metadata': {}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-pro-preview-05-06'}, 'type': 'AIMessageChunk', 'id': 'run--7876090c-6a73-4d2c-905f-9bad82d1940a', 'tool_calls': [{'name': 'get_exchange_rate', 'args': {'currency_to': 'SEK', 'currency_date': '2025-05-20', 'currency_from': 'USD'}, 'id': 'e59f289a-256a-42cc-b6d9-0510512d0b78', 'type': 'tool_call'}], 'usage_metadata': {'input_tokens': 56, 'output_tokens': 26, 'total_tokens': 177}, 'tool_call_chunks': [{'name': 'get_exchange_rate', 'args': '{\"currency_to\": \"SEK\", \"currency_date\": \"2025-05-20\", \"currency_from\": \"USD\"}', 'id': 'e59f289a-256a-42cc-b6d9-0510512d0b78', 'index': None, 'type': 'tool_call_chunk'}], 'invalid_tool_calls': []}}]\n",
      "\n",
      "------\n",
      "\n",
      "Message:\n",
      "\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'FunctionMessage'], 'kwargs': {'content': '{\"amount\": 1.0, \"base\": \"USD\", \"date\": \"2025-05-20\", \"rates\": {\"SEK\": 9.682}}', 'type': 'function', 'name': 'get_exchange_rate'}}]\n",
      "\n",
      "------\n",
      "\n",
      "Message:\n",
      "\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'The exchange rate from USD to SEK on May 20, 2025, is 9.682.', 'type': 'ai', 'tool_calls': [], 'invalid_tool_calls': []}}]\n",
      "\n",
      "------\n",
      "\n",
      "Output:\n",
      "\n",
      "The exchange rate from USD to SEK on May 20, 2025, is 9.682.\n"
     ]
    }
   ],
   "source": [
    "message_types = {\"actions\": \"Action\", \"messages\": \"Message\", \"output\": \"Output\"}\n",
    "for chunk in agent.stream_query(\n",
    "    input=f\"What's the exchange rate from USD to SEK {today}?\"\n",
    "):\n",
    "    for key, label in message_types.items():\n",
    "        if key in chunk:\n",
    "            print(\"\\n------\\n\")\n",
    "            print(f\"{label}:\")\n",
    "            print()\n",
    "            print(chunk[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77b0a9f0d75b"
   },
   "source": [
    "### Vertex AI에 에이전트 배포하기\n",
    "- Deploy your agent on Vertex AI\n",
    "\n",
    "- 이전 단계에서 에이전트에 대한 모델, 도구, 추론을 지정하고 테스트하고 동작을 확인했습니다.\n",
    "- 이제 Vertex AI에 원격 서비스로 에이전트를 배포할 준비가 되었습니다!\n",
    "\n",
    "<img width=\"40%\" src=\"https://storage.googleapis.com/github-repo/generative-ai/gemini/agent-engine/images/agent-stack-4.png\" alt=\"Components of an agent in Agent Engine on Vertex AI\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 에이전트를 재정의합니다.\n",
    "이전 셀의 로컬 테스트로 에이전트의 상태 저장 정보가 남아있는 것을 방지하기 위해서입니다. \n",
    "\n",
    "```bash\n",
    "# 이전 셀 (편의를 위해 복사)\n",
    "agent = LangchainAgent(\n",
    "    model=model,\n",
    "    tools=[get_exchange_rate],\n",
    "    agent_executor_kwargs={\"return_intermediate_steps\": True},\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b2f8365735d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = LangchainAgent(\n",
    "    model=model,\n",
    "    tools=[get_exchange_rate],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebe2c3be1ca6"
   },
   "source": [
    "`agent_engines.create()`를 호출해서 Vertex AI의 에이전트 엔진에 에이전트를 배포합니다.\n",
    "\n",
    "다음 정보를 argument로 제공합니다.\n",
    "- `agent`: 에이전트 클래스의 인스턴스\n",
    "- `requirements`: 런타임에 에이전트가 필요로 하는 Python 패키지 및 버전\n",
    "  - `requirements.txt` 파일에서 패키지 및 버전을 정의하는 방식과 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified the following requirements: {'cloudpickle': '3.1.1', 'pydantic': '2.11.0', 'google-cloud-aiplatform': '1.93.1'}\n",
      "The following requirements are missing: {'cloudpickle', 'pydantic', 'google-cloud-aiplatform'}\n",
      "The following requirements are appended: {'pydantic==2.11.0', 'cloudpickle==3.1.1'}\n",
      "The final list of requirements: ['google-genai', 'langchain', 'langchain-google-vertexai', 'pydantic==2.11.0', 'cloudpickle==3.1.1']\n",
      "Using bucket qwiklabs-gcp-00-b89ebc63afce\n",
      "Wrote to gs://qwiklabs-gcp-00-b89ebc63afce/agent_engine/agent_engine.pkl\n",
      "Writing to gs://qwiklabs-gcp-00-b89ebc63afce/agent_engine/requirements.txt\n",
      "Creating in-memory tarfile of extra_packages\n",
      "Writing to gs://qwiklabs-gcp-00-b89ebc63afce/agent_engine/dependencies.tar.gz\n",
      "Creating AgentEngine\n",
      "Create AgentEngine backing LRO: projects/214419441240/locations/us-central1/reasoningEngines/4888701375975784448/operations/8667683636180418560\n",
      "View progress and logs at https://console.cloud.google.com/logs/query?project=qwiklabs-gcp-00-b89ebc63afce\n",
      "AgentEngine created. Resource name: projects/214419441240/locations/us-central1/reasoningEngines/4888701375975784448\n",
      "To use this AgentEngine in another session:\n",
      "agent_engine = vertexai.agent_engines.get('projects/214419441240/locations/us-central1/reasoningEngines/4888701375975784448')\n"
     ]
    }
   ],
   "source": [
    "remote_agent = agent_engines.create(\n",
    "    agent,\n",
    "    requirements=[\n",
    "        \"google-genai\",\n",
    "        \"langchain\",\n",
    "        \"langchain-google-vertexai\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 16:28:42.044654\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e698a4c3d786"
   },
   "source": [
    "#### 원격 에이전트 테스트\n",
    "예상대로 작동하는지 원격 에이전트를 테스트합니다.\n",
    "- `.query`: 에이전트는 입력을 처리 완료 시 전체 출력을 단일 응답으로 반환합니다\n",
    "- `.stream_query`: 에이전트는 응답을 생성 즉시 여러 조각으로 나누어서 반환합니다.\n",
    "\n",
    "`.query`를 사용해서 원격에 배포된 에이전트에 프롬프트를 전송합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d01b37cb77dc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the exchange rate from USD to SEK 2025-05-20?\",\n",
       " 'output': 'The exchange rate from USD to SEK on May 20, 2025 is 9.682.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent.query(\n",
    "    input=f\"What's the exchange rate from USD to SEK {today}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff3620f5fa01"
   },
   "source": [
    "`.stream_query`로 원격 에이전트의 중간 결과를 스트리밍합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "a4250671731e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------\n",
      "\n",
      "Action:\n",
      "\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'agent', 'ToolAgentAction'], 'kwargs': {'tool': 'get_exchange_rate', 'tool_input': {'currency_from': 'USD', 'currency_date': '2025-05-20', 'currency_to': 'SEK'}, 'log': \"\\nInvoking: `get_exchange_rate` with `{'currency_from': 'USD', 'currency_date': '2025-05-20', 'currency_to': 'SEK'}`\\n\\n\\n\", 'type': 'AgentActionMessageLog', 'message_log': [{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'content': '', 'additional_kwargs': {'function_call': {'name': 'get_exchange_rate', 'arguments': '{\"currency_from\": \"USD\", \"currency_date\": \"2025-05-20\", \"currency_to\": \"SEK\"}'}}, 'response_metadata': {'safety_ratings': [], 'usage_metadata': {}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-pro-preview-05-06'}, 'type': 'AIMessageChunk', 'id': 'run--4d3844d9-b359-45f4-a351-8302d6b06034', 'tool_calls': [{'name': 'get_exchange_rate', 'args': {'currency_from': 'USD', 'currency_date': '2025-05-20', 'currency_to': 'SEK'}, 'id': 'd3df0a8a-ab85-448b-9ea5-a2fab8aae06c', 'type': 'tool_call'}], 'usage_metadata': {'input_tokens': 56, 'output_tokens': 26, 'total_tokens': 211}, 'tool_call_chunks': [{'name': 'get_exchange_rate', 'args': '{\"currency_from\": \"USD\", \"currency_date\": \"2025-05-20\", \"currency_to\": \"SEK\"}', 'id': 'd3df0a8a-ab85-448b-9ea5-a2fab8aae06c', 'index': None, 'type': 'tool_call_chunk'}], 'invalid_tool_calls': []}}], 'tool_call_id': 'd3df0a8a-ab85-448b-9ea5-a2fab8aae06c'}}]\n",
      "\n",
      "------\n",
      "\n",
      "Message:\n",
      "\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessageChunk'], 'kwargs': {'content': '', 'additional_kwargs': {'function_call': {'name': 'get_exchange_rate', 'arguments': '{\"currency_from\": \"USD\", \"currency_date\": \"2025-05-20\", \"currency_to\": \"SEK\"}'}}, 'response_metadata': {'safety_ratings': [], 'usage_metadata': {}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-pro-preview-05-06'}, 'type': 'AIMessageChunk', 'id': 'run--4d3844d9-b359-45f4-a351-8302d6b06034', 'tool_calls': [{'name': 'get_exchange_rate', 'args': {'currency_from': 'USD', 'currency_date': '2025-05-20', 'currency_to': 'SEK'}, 'id': 'd3df0a8a-ab85-448b-9ea5-a2fab8aae06c', 'type': 'tool_call'}], 'usage_metadata': {'input_tokens': 56, 'output_tokens': 26, 'total_tokens': 211}, 'tool_call_chunks': [{'name': 'get_exchange_rate', 'args': '{\"currency_from\": \"USD\", \"currency_date\": \"2025-05-20\", \"currency_to\": \"SEK\"}', 'id': 'd3df0a8a-ab85-448b-9ea5-a2fab8aae06c', 'index': None, 'type': 'tool_call_chunk'}], 'invalid_tool_calls': []}}]\n",
      "\n",
      "------\n",
      "\n",
      "Message:\n",
      "\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'FunctionMessage'], 'kwargs': {'content': '{\"amount\": 1.0, \"base\": \"USD\", \"date\": \"2025-05-20\", \"rates\": {\"SEK\": 9.682}}', 'type': 'function', 'name': 'get_exchange_rate'}}]\n",
      "\n",
      "------\n",
      "\n",
      "Message:\n",
      "\n",
      "[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'The exchange rate from USD to SEK on May 20, 2025, is 9.682.', 'type': 'ai', 'tool_calls': [], 'invalid_tool_calls': []}}]\n",
      "\n",
      "------\n",
      "\n",
      "Output:\n",
      "\n",
      "The exchange rate from USD to SEK on May 20, 2025, is 9.682.\n"
     ]
    }
   ],
   "source": [
    "message_types = {\"actions\": \"Action\", \"messages\": \"Message\", \"output\": \"Output\"}\n",
    "for chunk in remote_agent.stream_query(\n",
    "    input=f\"What's the exchange rate from USD to SEK {today}?\"\n",
    "):\n",
    "    for key, label in message_types.items():\n",
    "        if key in chunk:\n",
    "            print(\"\\n------\\n\")\n",
    "            print(f\"{label}:\")\n",
    "            print()\n",
    "            print(chunk[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f2f7d3ed7bd"
   },
   "source": [
    "### 배포된 에이전트에 쿼리하기\n",
    "- Querying your deployed agent\n",
    "\n",
    "에이전트를 배포했으므로 다른 애플리케이션이나 환경에서도 [다양한 방식으로 에이전트와 상호작용](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/use/overview)할 수 있습니다. \n",
    "\n",
    "#### 방법 1: 이 노트북을 이용\n",
    "이 노트북에서 생성한 `remote_agent` 인스턴스를 직접 재사용하고 쿼리할 수 있습니다.\n",
    "그 외의 다양한 방식 중 대표적인 방법은 Python 클라이언트 라이브러리를 이용하거나 REST API를 호출하는 것입니다. 두 가지 방법 추가적으로 소개합니다.\n",
    "\n",
    "#### 방법 2: 다른 Python 환경을 이용\n",
    "\n",
    "다른 환경에서 노트북이나 Python 스크립트를 실행하는 새 인스턴스를 생성할 수 있습니다. 에이전트를 생성한 노트북 또는 환경에서 코드를 실행합니다.\n",
    "이렇게 하려면 에이전트를 고유하게 식별하는 배포된 에이전트의 리소스 이름을 검색해야 합니다. 이 리소스 이름은 프로젝트, 위치 및 에이전트 엔진 ID를 포함하는 문자열입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fdaf8b91413f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/318444459587/locations/europe-west1/reasoningEngines/915391808635142144'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "060f8369d113"
   },
   "source": [
    "리소스 이름을 사용하여 다른 노트북이나 Python 스크립트에서 에이전트를 로드한 다음, 원격 에이전트에 쿼리하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "78af4442827e"
   },
   "outputs": [],
   "source": [
    "# from vertexai import agent_engines\n",
    "\n",
    "# AGENT_ENGINE_RESOURCE_NAME = \"YOUR_AGENT_ENGINE_RESOURCE_NAME\"  # Replace with the resource name of your deployed Agent Engine\n",
    "\n",
    "# remote_agent = agent_engines.get(AGENT_ENGINE_RESOURCE_NAME)\n",
    "# response = remote_agent.query(input=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai import agent_engines\n",
    "\n",
    "AGENT_ENGINE_RESOURCE_NAME = \"projects/318444459587/locations/europe-west1/reasoningEngines/915391808635142144\"  # Replace with the resource name of your deployed Agent Engine\n",
    "\n",
    "remote_agent = agent_engines.get(AGENT_ENGINE_RESOURCE_NAME)\n",
    "\n",
    "query=f\"What's the exchange rate from USD to SEK {today}?\"\n",
    "\n",
    "response = remote_agent.query(input=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': 'The exchange rate from USD to SEK on 2025-05-13 was 9.7422.', 'input': \"What's the exchange rate from USD to SEK 2025-05-14?\"}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63ab06554fc0"
   },
   "source": [
    "#### 방법 3: REST API를 통해 다른 환경에서 액세스하기\n",
    "Python 클라이언트 라이브러리 외에도, 배포된 Vertex AI 에이전트는 [REST API 호출을 사용하여 쿼리](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/use/overview)할 수 있습니다.\n",
    "\n",
    "- Python: Python의 `requests` 라이브러리나 유사한 도구를 사용하여 Vertex AI REST API에 HTTP 호출을 할 수 있습니다.\n",
    "- cURL: 명령줄 도구인 `cURL`을 사용하면 HTTP 요청을 직접 보낼 수 있습니다. 이 방법은 테스트 및 디버깅에 유용합니다.\n",
    "- 다른 프로그래밍 언어: 애플리케이션에 다른 언어를 선호하는 경우 해당 언어의 기본 HTTP 클라이언트 라이브러리를 사용하여 REST API 호출을 할 수 있습니다.\n",
    "\n",
    "요약하면, Python 환경 내에서는 Python 클라이언트 라이브러리를 통해 배포된 에이전트에 액세스할 수 있으며, 더 보편적으로 사용자가 선택한 도구 및 프로그래밍 언어를 통해 해당 REST API를 통해 액세스할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya29.c.c0ASRK0GY5VEZ51k--7NW2x_h40RSBILi2XoR3OQlAKtPwW7UTjzT_jvI_JoD3UH6DtOrNV47PRuN0sznQj0agVavqgTKByHBsdFQfFIg7x_7Wa5QbDAyVJbMbeihq0edMHs6IOMFsq5BH58-iqapdVCHHP8OXnw6jG56nRqs4VcBbYaRDYjbc2y7sY1mqWsWcrXJZUZpRnD8wQ-pYZ7KhRUPYUJRPKsDMqyWOY2v50nAqGyHAKu3G4WBW3bIECGfnasBtUNzBkbGaMEQNEMoLY1OxxGP5UTKbIkvyO5yT5ztMcCs8sZekt0wyvo8FCivVqb7TQA0rTqGP7lzGXYfIdq0u9RqxKEWvFSGapQD2q1M9z_QHcGfiaEVE-2z-YFWqYFKgGgJ6QkYjqtIe_VRBG413KV5p6z0tcMOxsV06gV0x3ImouyzMj4IkIBR2dRprjfc5SXYFbyZoo23RMkV5kWymIhwU9_IF_1xXZzmbX1bMWn1YmWJM615aipkwtQ_lZSQy-OnJBd0OtMaFjX0RdZYFZx7coafYajhBpO_1buOl8w2vfSeeUahmltgpXqj3ju2oqzodhFajyhdY542_F7Ikj_9FnyozodgWgUk5Z9udixjQckuBbR37Rk5JBleSOya69q9cynr1VScXyWuWOj_FuvnW8kYXo51xhejnkO4FVwz565Faec4rcJwfplabtwJfuIjeW8bz9X9kkOuUbj3lbgX1hlyh_SF6IR8Ujie7U3O5WM_8X34InWhlmdcRS8jx0WuRxvStowhFOwqmjVzxXir6lUog-huFe19a0OF87hM-exYxWrSn4sXtWUl1u2y2akQISfp359Jky3R_Xwe0hR9M-3cdIjaUV44Sz9XIokjW7udWmMz7YdmkSBWqSy-gn5joXqQ-Xr4Jsx9qvdzuJt490ZSOo-uXRFWoXgUYSuxqYFouFg41lFwFWjSrw_7rROfxvRwh0oX-yXROn-mBiiJemuXIhrVfIXoya7y-ytsXadz240e\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth print-access-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import date\n",
    "\n",
    "# 1. Configuration\n",
    "agent_engine_resource_name = \"projects/318444459587/locations/europe-west1/reasoningEngines/915391808635142144\"  # Replace with your Agent Engine resource name\n",
    "location = \"europe-west1\"  # Replace with your Agent Engine location\n",
    "access_token = \"ya29.c.c0ASRK0GY5VEZ51k--7NW2x_h40RSBILi2XoR3OQlAKtPwW7UTjzT_jvI_JoD3UH6DtOrNV47PRuN0sznQj0agVavqgTKByHBsdFQfFIg7x_7Wa5QbDAyVJbMbeihq0edMHs6IOMFsq5BH58-iqapdVCHHP8OXnw6jG56nRqs4VcBbYaRDYjbc2y7sY1mqWsWcrXJZUZpRnD8wQ-pYZ7KhRUPYUJRPKsDMqyWOY2v50nAqGyHAKu3G4WBW3bIECGfnasBtUNzBkbGaMEQNEMoLY1OxxGP5UTKbIkvyO5yT5ztMcCs8sZekt0wyvo8FCivVqb7TQA0rTqGP7lzGXYfIdq0u9RqxKEWvFSGapQD2q1M9z_QHcGfiaEVE-2z-YFWqYFKgGgJ6QkYjqtIe_VRBG413KV5p6z0tcMOxsV06gV0x3ImouyzMj4IkIBR2dRprjfc5SXYFbyZoo23RMkV5kWymIhwU9_IF_1xXZzmbX1bMWn1YmWJM615aipkwtQ_lZSQy-OnJBd0OtMaFjX0RdZYFZx7coafYajhBpO_1buOl8w2vfSeeUahmltgpXqj3ju2oqzodhFajyhdY542_F7Ikj_9FnyozodgWgUk5Z9udixjQckuBbR37Rk5JBleSOya69q9cynr1VScXyWuWOj_FuvnW8kYXo51xhejnkO4FVwz565Faec4rcJwfplabtwJfuIjeW8bz9X9kkOuUbj3lbgX1hlyh_SF6IR8Ujie7U3O5WM_8X34InWhlmdcRS8jx0WuRxvStowhFOwqmjVzxXir6lUog-huFe19a0OF87hM-exYxWrSn4sXtWUl1u2y2akQISfp359Jky3R_Xwe0hR9M-3cdIjaUV44Sz9XIokjW7udWmMz7YdmkSBWqSy-gn5joXqQ-Xr4Jsx9qvdzuJt490ZSOo-uXRFWoXgUYSuxqYFouFg41lFwFWjSrw_7rROfxvRwh0oX-yXROn-mBiiJemuXIhrVfIXoya7y-ytsXadz240e\"  # Replace with the token obtained from 'gcloud auth print-access-token'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Construct the API Endpoint URL\n",
    "api_endpoint = f\"https://{location}-aiplatform.googleapis.com/v1beta1/{agent_engine_resource_name}:query\"\n",
    "\n",
    "# 3. Prepare the Request Headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Response:\n",
      "{'output': {'output': 'OK. The exchange rate from USD to SEK on 2025-05-13 is 9.7422.', 'input': \"What's the exchange rate from USD to SEK 2025-05-14?\"}}\n",
      "\n",
      "Agent Output: {'output': 'OK. The exchange rate from USD to SEK on 2025-05-13 is 9.7422.', 'input': \"What's the exchange rate from USD to SEK 2025-05-14?\"}\n"
     ]
    }
   ],
   "source": [
    "# 4. Prepare the Request Body (Payload)\n",
    "today = str(date.today())\n",
    "#query_input \n",
    "query_string = f\"What's the exchange rate from USD to SEK {today}?\"\n",
    "#payload = {\n",
    "#    \"input\": query_input\n",
    "#}\n",
    "\n",
    "payload = {\n",
    "    \"input\": {  # This 'input' field must be a JSON object (Struct)\n",
    "        \"input\": query_string  # We'll assume the agent expects the query string under a key named \"input\" within the Struct.\n",
    "                               # If this specific key doesn't work, common alternatives are \"query\", \"text\", or \"prompt\".\n",
    "                               # You may need to check your Agent's tool input schema if \"input\" as a key doesn't work.\n",
    "    }\n",
    "}\n",
    "\n",
    "# 5. Make the POST Request\n",
    "try:\n",
    "    response = requests.post(api_endpoint, headers=headers, data=json.dumps(payload))\n",
    "    response.raise_for_status()  # Raises an HTTPError for bad responses (4XX or 5XX)\n",
    "\n",
    "    # 6. Process the Response\n",
    "    response_data = response.json()\n",
    "    print(\"API Response:\")\n",
    "    print(response_data)\n",
    "    # Example of accessing specific parts of the response, matching your previous output structure\n",
    "    # This might vary slightly depending on the exact API version and agent configuration\n",
    "    if 'output' in response_data:\n",
    "        print(f\"\\nAgent Output: {response_data['output']}\")\n",
    "    if 'input' in response_data: # The API might return the processed input or the original one\n",
    "        print(f\"Processed Input by Agent: {response_data.get('input', 'N/A')}\")\n",
    "\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "    print(f\"Response content: {response.content}\")\n",
    "except Exception as err:\n",
    "    print(f\"Other error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82d321fd62e0"
   },
   "source": [
    "## 에이전트 맞춤설정\n",
    "- Customizing your agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "353d586b9b1b"
   },
   "source": [
    "지금까지 에이전트의  각 구성 요소에 필요한 최소한의 구성만을 포함한 예제를 봤습니다. 에이전트에 맞춤설정을 하려면 어떻게 해야 할까요? 예를 들어 Gemini 모델 버전을 변경하거나, 생성형 모델의 매개변수나 안전 필터를 변경하는 경우를 예상할 수 있습니다.\n",
    "아래 예는 에이전트의 맞춤설정을 하는 대표적인 매개변수를 보여줍니다. \n",
    "\n",
    "#### 주의 \n",
    "Vertex AI의 에이전트 엔진은 [함수 호출을 지원하는 Gemini 모델 버전](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling) 및 LangChain 에이전트와 함께 작동합니다. 그러므로 해당 버전의 함수 호출 지원 여부를 확인해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdda38e6dc6b"
   },
   "source": [
    "### 모델 구성 (Model configuration)\n",
    "에이전트 내 모델 구성 요소에 대한 맞춤설정부터 시작합니다. [생성형 AI 모델 버전](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions?hl=ko), [안전 및 콘텐츠 필터 속성](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters?hl=ko) 및 [모델 매개변수](https://ai.google.dev/gemini-api/docs/models?hl=ko#model-attributes)와 관련된 구성 매개변수에 대한 자세한 내용은 Vertex AI 문서를 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5408d3da2726"
   },
   "outputs": [],
   "source": [
    "## Model variant and version\n",
    "model = \"gemini-2.0-flash\"\n",
    "\n",
    "## Model safety settings\n",
    "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}\n",
    "\n",
    "## Model parameters\n",
    "model_kwargs = {\n",
    "    \"temperature\": 0.3,\n",
    "    \"max_output_tokens\": 1000,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 40,\n",
    "    \"safety_settings\": safety_settings,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e48ed43107e"
   },
   "source": [
    "### 에이전트 구성 (Agent configuration)\n",
    "입력 프롬프트와 출력 응답에 대한 모든 중간 단계의 반환 여부, 최대 반복 횟수, 파싱 오류 처리 방법, 에이전트가 볼 수 있는 슬라이딩 컨텍스트 창 크기 등 에이전트 구성 요소의 여러 측면을 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "08623f46a9e4"
   },
   "outputs": [],
   "source": [
    "# Agent parameters\n",
    "agent_executor_kwargs = {\n",
    "    \"return_intermediate_steps\": True,\n",
    "    \"max_iterations\": 3,\n",
    "    \"handle_parsing_errors\": False,\n",
    "    \"trim_intermediate_steps\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "164b7a580493"
   },
   "source": [
    "에이전트 내 각 구성 요소에는 시스템 명령어, 머리말 프롬프트, 채팅 세션 및 기록 관리 기능(에이전트가 여러 차례의 질의응답 간에 컨텍스트를 유지하도록 함)을 포함해서 맞춤설정하거나 재정의할 수 있는 추가 매개변수가 있습니다. 에이전트 내 각 구성 요소(모델, 도구, 추론)는 모듈식이라 조합이 가능하므로 원하는 만큼 에이전트를 맞춤설정할 수 있습니다. 각 에이전트의 구성 요소 및 사용 가능한 맞춤설정 옵션에 대한 자세한 내용은 [Vertex AI의 에이전트 엔진 문서](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)를 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6415b2a47a0e"
   },
   "source": [
    "## 정리\n",
    "- 작업을 마친 후에는 클라우드 리소스를 정리하는 것이 좋습니다.\n",
    "    - 배포된 Agent Engine 인스턴스를 삭제할 수 있습니다.   \n",
    "    - Google Cloud 계정에 예상치 못한 요금이 발생하는 것을 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7cec827288b7"
   },
   "outputs": [],
   "source": [
    "remote_agent.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_agent_engine.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
